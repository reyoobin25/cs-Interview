---
layout: post
title: "[Interview] OS"
date: 2019-08-27 15:03:00
categories: interview
permalink: /interview/os
---



# CS기본 - 운영체제(OS)

1. **<mark>운영체제</mark>**

   - **정의** : 컴퓨터 하드웨어와 컴퓨터 사용자 간의 매개체 역할을 하는 시스템 소프트웨어 

   - **목적** : 

     - 프로세스 관리 : CPU를 어떻게 하면 효율적으로 사용할 수 있을지 생각해 스케줄링 하는 것으로  작업 시간을 할당하거나, 작업의 우선순위를 부여해 효율적으로 실행되도록 프로세스를 관리하는 것

     - 기억장치 관리 : 한정된 자원인 RAM, HW를 효율적으로 사용, 프로그램에게 기억 공간이 필요할 때 할당, 회수를 하면서 기억공간을 효율적으로 사용할 수 있도록 한다.

     - 파일 관리 : 각 파일의 이름과 보조 기억 장치의 저장영역을 기억해 주었다가 필요할 때 접근해  파일을 저장, 삭제, 복사, 이동, 검색등을 한다.

     - 입출력장치 관리 : 마우스나 키보드 등으로 컴퓨터에 입력되는 정보나 프린터기 컴퓨터 화면과 같이 출력되는 정보들을 관리한다.

   - **성능향상** :

     - 처리량(Throughput) 증대 : 일정한 시간안에 더 많은 작업을 수행
     - 응답시간(Turn-around Time)의 단축 : 어떠한 프로세스가 작업을 요구했을 때 더 빨리 응답하는 것
     - 신뢰성(Reliability) : 운영체제의 오류 등을 줄여서 사용자에게 운영체제의 신뢰성을 높임
     - 사용도(availability) : 명령어 등을 이용해 쉽게 접근할 수 있도록 함

2. **<mark>운영체제 유형</mark>**

   - **일괄처리 시스템(batch processing system)**

     - 유사한 작업끼리 묶어서 한번에 한 작업씩 순서대로 처리

     - 유휴 상태의 시간을 없애기 위해 작업 순서의 자동화 개념 도입

     - 작업의 준비 및 실행 순서를 자동화함으로써 시스템의 성능을 증진

       ![os_batchpro](/img/os_batchpro.JPG)

       <그림출처 : http://sunrint10103.tistory.com/>

   - **다중프로그래밍 시스템( multiprogramming system)**

     - 여러개의 프로그램을 동시에 메모리(RAM)에 적재시켜놓고, <u>CPU를 나눠쓰게 하는 시스템</u>CPU가 항상 수행되도록해 그 이용도를 높이기 위한 방안

     - 주기억장치(RAM) 내에 동시에 여러 프로그램들이 존재하도록 함 > <u>철저한 메모리관리 필요</u> <u>어떤 프로그램에게 먼저 CPU를 할당할 것인지에 대한 스케줄링도 필요</u>

   - **다중처리 시스템(multiprocessing system)**

     - 2개 이상의 프로세서가 동시에 동작하는 프로그램으로 여러개의 프로세서가 작업을 한다.

     - 하나의 CPU가 장애를 일으키더라도 다른 CPU가 작동할 수 있어 신뢰도 향상

     - 여러개의 CPU로 신속한 처리가 가능하지만 운영체제의 세심한 설계가 필요

     - 공유기억장치(common memory)를 통해 하나로 연결된 다중처리기의 제어 및 공유를 위한 시스템

       ![os_multipro](/img/os_multipro.JPG)

       <그림출처 : 운영체제-박규석(생능출판사)>

   - **시분할 시스템(time-sharing system)**

     - 다중프로그래밍 방식을 변형한 것으로 CPU를 아주 짧은 시간동안 돌아가면서 사용하는 방식

     - 여러명의 사용자들이 돌아가면서 컴퓨터 자원에 대한 짧은 시간 단위의 sharing

     - 메모리에 여러 사용자의 프로그램이 적재되어야 함으로 다중프로그래밍 환경이 지원되야 하며 어떤사용자에게 먼저 CPU를 할당할건지에 대한 관리가 필요, 또한 여러명의 사용자가 RAM에 접근해 입출력 장치나 파일들을 공유하기에 그 정보들에 대한 보호와 접근제어가 필요하다.

       ![os_timeshare](/img/os_timeshare.JPG)

       <그림출처 : 운영체제-박규석(생능출판사)>

   - **실시간 시스템(real-time system)**

     - 외부의 제어 대상으로부터 입력되는 데이터를 짧은 시간, 또는 특정시간 내에 결과를 출력하거나 응답하는것, 데이터가 무작위로 갑자기 날아오기 떄문에 빠른 입출력 장치가 필요, 동시에 데이터가 날아오는 것을 예방하기 위해 우선순위를 잘 짜야한다.
     - 매우 엄격하게 정의되어있는 시간 제약 등과 같은 사건들의 제시된 상황을 분석 사전에 정의된 제약 내에서 수행되어야 함

   - **분산처리 시스템(distributed processing system)**

     - 각 시스템은 자신의 운영체제와 메모리, 프로세스를 가지고 있어서 독립적으로 운영되지만 필요할 때 서로 통신하는 시스템이다.
     - 사용자의 접근을 제어하면서 CPU, 입출력장치 등 동시에 사용하는 자원을 편리하게 공유한다.
     - 프로세서들이 기억장치와 클럭을 공유하지 않으며 각 프로세서들은 자신의 지역(local) 기억장치 보유프로세서들은 고속의 버스(bus)나 전화선과 같은 다양한 통신라인을 통해 서로 통신

3. **<mark>프로세스와 스레드</mark>**

   - **프로그램(program)** : 어떤 작업을 위해 실행할 수 있는 파일

   - **프로세스(process)** : 

     정의

     - 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램

     - PCB(process control block)를 지닌 프로그램

       +(PCB? 프로세스에 관한 모든 정보를 가지고 있는 데이터베이스)

     - 프로그램 카운터를 지닌 프로그램

     - 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(독립적인 개체)

     - 운영체제로부터 시스템 자원(CPU시간, 운영되기 위해 필요한 주소 공간)을 할당받는 작업의 단위

     구성요소 4가지

     - 코드(code)영역 : 프로그램의 코드 자체, 프로그램은 실행되기 전에 주기억장치에 CPU가 해석할 수 있는 바이너리 코드 상태로 주기억장치에 올라가게 되는 영역
     - 데이터(data) 영역 : 프로그램의 전역변수나 정적변수의 할당
     - 스택(stack) 영역 : 지역변수 할당과 함수 호출 시 전달되는 인자값
     - 힙(heap) 영역 : 동적할당

     특징

     - 프로세스강 최소 1개의 메인 스레드를 가지고 있다.

     - 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근이 불가하다.

     - 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신을 사용해야한다.(ex.파이프, 파일, 소켓등을 이용한 통신 방법)

       ![os_process](/img/os_process.JPG)

       <그림출처 : <https://gmlwjd9405.github.io/2017/10/01/basic-concepts-of-development-os.html>>

   - **스레드(Thread)** :

     정의

     - 프로세스 내에서 실행되는 여러 흐름의 단위
     - 프로세스가 할당받은 자원을 이용하는 실행의 단위

     특징

     - 스레드는 프로세스 내에서 각각 Stack만 따로 할당 받고, Code, Data, Heap영역은 공유한다.

     - 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다.

     - 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다.

       ![os_process](/img/os_thread.JPG)

       <그림출처 : <https://gmlwjd9405.github.io/2017/10/01/basic-concepts-of-development-os.html>>

4. **<mark>멀티 프로세스(multi process)와 멀티 스레드(multi thread)의 차이</mark>**

   - **공통점** : 동시에 두 가지 이상의 루틴을 실행할 수 있는 역할

   - **멀티 프로세스(multi process)**

     - 부모 - 자식관계여도 자신만의 메모리 영역을 가지게 된다.
     - 환경변수와 프로세스 핸들 테이블이 상속 가능할 뿐 결국 독립적인 관계이다.
     - fork()를 통해 프로세스를 복사한다.
     - 유닉스에서 ps명령어로 현재 수행중인 프로세스 확인이 가능하다.
     - 프로세스 간의 통신을 하려면 IPC(Inter Process Communication)를 통해야 한다.

   - **멀티 스레드(multi thread)**

     - 하나의 프로세스가 다수 개의 작업을 각각 스레드를 이용하여 동시에 작동 시킬 수 있다.

       ![os_multithread](/img/os_multithread.JPG)

       <그림출처 :  <https://gmlwjd9405.github.io/2017/10/01/basic-concepts-of-development-os.html>>

   - **멀티 프로세스 대신 멀티 스레드를 사용하는 이유?**

     - 프로그램을 여러 개 키는 것보다 하나의 프로그램 안에서 여러 작업하는 것이 더 이득인 이유

     - Context Switching : 프로세스 간의 Context Switching시 단순히 CPU레지스터 교체 뿐만이 아니라 RAM과 CPU사이의 캐쉬메모리에 대한 데이터까지 초기화되므로 상당한 부담이 발생한다.

       +(Context Switching? 한 프로세스에서 다른 프로세스로 CPU가 할당되는 과정)

     - memory 공유 : stack을 제외한 모든 메모리 공유가 가능하여 프로세스 통신과 같은 복잡한 과정을 거치지 안고 효율적인 일처리가 가능하다.

   - **결론** : 완전히 별개의 프로그램이라면 독립적인 프로세스를 구성해야겠지만 서로 관련된 기능들을 가진 프로그램이라면 기능들을 멀티 스레드로 구현하는 것이 더 이득이 된다.

     <출처 : <https://you9010.tistory.com/136>>

5. **<mark>Thread-safe</mark>**

   정의

   - 멀티 스레드환경에서 여러 스레드가 동시에 하나의 객체 및 변수(공유자원)에 접근할 때, 의도한 대로 동작하는 것을 말한다.

   Thread-safe구현

   - Thread-safe를 하기 위해서는 공유 자원에 접근하는 <u>임계영역(critical section)</u>을 동기화 기법으로 제어해줘야 한다. 이를 <u>상호배제</u>하고 하며 이러한 동기화 기법에는 <u>뮤텍스(Mutex)와 세마포어(Semaphore)</u>가 있다.

6. **<mark>프로세스 스케줄링</mark>**

   목적 : 응답 시간의 최소화, 오버헤드 최소화, 자원 사용의 균형 유지, 실행의 무한한 지연을 피함

   방법 분류 : 

   - **선점/비선점 기법**

     - 비선점 기법: 하나의 프로세스에 중앙처리장치가 할당되면 그 프로세스의 수행이 끝날 때까지 중앙처리장치는 그 프로세스로부터 빠져나올 수 없다.
     - 선점 기법: 하나의 프로세스가 중앙처리장치를 차지하고 있을 때 다른 프로세스가 현재 수행중인 프로세스를 중지시키고 자신이 중앙처리장치를 차지할 수 있다.

   - **우선순위(priority) 기법**

     - 각 프로세스에게 우선순위를 부여하여 우선순위가 높은 순서대로 처리하는 방법

     - 정적 우선순위(static priority)기법 : 상대적으로 오버헤드는 적으나, 주위 여건의 변화에

       적응하지 않고 우선순위를 바꾸지 않는다.

     - 동적 우선순위(dynamic priority) 기법 : 필요에 따라 우선순위 재구성

   스케줄링 예시 :

   - **FCFS(First Come First Served) 스케줄링**

     - 가장 간단한 스케줄링 방식, 비선점 스케줄링 방법
     - 프로세스들은 대기 큐에 도착한 순서에 따라 중앙처리장치를 할당
     - 호위효과(convoy effect) : 첫번째 프로세스가 끝날 때까지 매우 긴 시간을 기다리게 되는 것
     - 먼저 도착한 프로세스가 CPU에서 수행되는 버스트 시간이 매우 길면, 그 다음 도착한 프로세스가 첫 번째 프로세스가 끝날 때까지 매우 긴 시간을 기다리게 되는 것

   - **SJF(Shortest Job First) 스케줄링**

     - 비선점 방식

     - 프로세스 중에서 수행시간이 가장 짧은 것을 먼저 수행하는 비 선점 스케줄링 방식

     - 문제점 : 

       수행될 프로세스나 프로세스가 얼마나 긴 것인가를 정확히 알아야 하는데, 이 정보를 얻기가 어려움

   - **Priority 스케줄링**

     - 각 프로세스에게 주어지며, 중앙처리장치는 가장 높은 우선순위를 가진 프로세스로 할당

     - 문제점 : 

       -무한대기(indefinite blocking)또는 기아현상(starvation) : 낮은 우선순위의 프로세스들이 중앙처리장치를 무한히 대기하는 경우

       -에이징(aging) : 낮은 우선순위 프로세스들의 무한 대기 문제에 대한 해결책, 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시키는 방법

   - **라운드로빈(Round-Robin) 스케줄링**

     - 시분할 시스템을 위하여 고안된 선점 스케줄링 방식

     - 각 프로세스는 같은 크기의 중앙처리장치 시간을 할당 받음

     - 할당시간(time quantum)의 크기는 보통 10에서 100ms사이

     - 할당시간이 너무크면 FCFS와 같은 형식이 되고, 너무 적으면 문맥교환을 위한 오버헤드가 커진다.

       <출처 : 운영체제-박규석(생능출판사)>

       <출처 : <https://github.com/WeareSoft/tech-interview/blob/master/contents/os.md>>

7. **<mark>동기(Synchronous)와 비동기(Asynchronous)</mark>**

   - **동기(Synchronous)**
     - 두 개의 프로세스가 데이터를 주고 받을 때, <u>주고 받는 순서(시간)가 일정하다는 것</u>이다.
     - 어떤 작업을 요청했을 때, 그 작업이 종료될 때까지 <u>기다린 후 다음 작업을 수행하는것</u>이다.
     - 데이터를 주고받는 '순서'가 중요할때 사용된다.
     - 요청한 작업만 처리하면 되기 때문에 전체적인 수행 속도는 빠를 수 있다.
     - 한 작업에 대한 시간이 길어질 경우, 전체 응답이 지연될 수 있다.
   - **비동기(Asynchronous)**
     - 어떤 작업을 요청했을 때 <u>그 작업이 종료될 때까지 기다리지 않고(작업을 위임하고), 다음 작업을 수행</u>한다. 
     - 요청했던 작업이 끝나면 결과를 받고, 그에 따른 추가 작업이 있다면 수행한다.
     - <u>요청 순서에 상관없이, 동시에 다수의 작업을 처리</u>할 수 있다.
     - 작업이 끝날 때 따로 이벤트를 감지하고 결과를 받아 그에 따른 추가 작업을 해줘야하기 때문에, 비교적 느릴 수 있다.
     - I/O 작업이 잦고, 빠른 응답속도를 요구하는 프로그램에 적합하다.

8. **<mark>뮤텍스(Mutex)와 세마포어(Semaphore)</mark>**

   - **뮤텍스(Mutex)** 

     - 공유된 자원의 데이터를 여러 <u>스레드</u>가 접근하는 것을 막는 것

     - Mutual Exclusion 으로 상호배제라고도 한다.  Critical Section을 가진 쓰레드들의 Runnig Time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술

     - 다중 프로세스들의 공유 리소스에 대한 접근을 조율하기 위해 locking과 synchronized 을 사용한다. 

     - 뮤텍스 객체를 두 쓰레드가 동시에 사용할 수 없다는 의미

       +Critical Section?   다중 프로그래밍 운영체제에서 여러 프로세스가 데이타를 공유하면서 수행될 때 각 프로세스에서 공유 데이터를 액세스하는 프로그램 코드 부분

   - **세마포어(Semaphore)** 

     - 공유된 자원의 데이터를 여러 <u>프로세스</u>가 접근하는 것을 막는 것
     - 리소스의 상태를 나타내는 간단한 카운터로 생각할 수 있다. 
     - 일반적으로 비교적 긴 시간을 확보하는 리소스에 대해 이용하게 되며, 유닉스 시스템의 프로그래밍에서 세마포어는 운영체제의 리소스를 경쟁적으로 사용하는 <u>다중 프로세스에서 행동을 조정하거나 또는 동기화 시키는 기술</u>이다. 
     - 세마포어는 운영체제 또는 커널의 한 지정된 저장장치 내 값으로서, 각 프로세스는 이를 확인하고 변경할 수 있다.
     - 세마포어는 이진수(0 또는 1)를 사용하거나, 또는 추가적인 값을 가질 수도 있습니다. 세마포어를 사용하는 프로세스는 그 값을 확인하고, 자원을 사용하는 동안에는 그 값을 변경함으로써 다른 세마포어 사용자들이 기다리도록 해야한다.

   - **차이점**

     - 동기화 갯수 : Mutex는 동기화 대상이 오직 하나뿐일 때, Semaphore는 동기화 대상이 하나 이상일때 사용한다.

       <출처 : <https://jwprogramming.tistory.com/13>>

9. **<mark>교착상태(Deadlock)</mark>**

   **개념**

   - 첫 번째 스레드는 두 번째 스레드가 들고 있는 객체의 락이 풀리기를 기다리고 있고, 두 번째 스레드 역시 첫 번째 스레드가 들고 있는 객체의 락이 풀리기를 기다리는 상황을 말한다.
   - 모든 스레드가 락이 풀리기를 기다리고 있기 때문에, 무한 대기 상태에 빠지게 된다. 이런 스레드를 교착상태에 빠졌다고 한다.
   - 하나 또는 그 이상의 프로세스가 발생될 수 없는 어떤 특정 사건을 기다리고 있는 상태 혹은 특정 프로세스가 특정한 자원을 위하여 무한정 기다려도 도저히 해결할 수 없는 상태
   - 프로세스가 자원을 얻지 못해 다음 처리를 하지 못하는 상태로, ‘교착 상태’라고도 하며 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생

   **데드락 발생 조건**

   - 교착상태는 한 시스템 내에서 4가지 조건이 동시에 성립할 때 발생한다. 하나라도 성립하지 않도록 만든다면 교착상태를 해결할 수 있다.
   - **(1) 상호배제(Mutual exclusion)**
     - 자원은 한 번에 한 프로세스만이 사용할 수 있어야 한다.
     - 적어도 하나의 자원은 반드시 비 공유 되는 상태에서 점유되어야 한다.
   - **(2) 점유대기(Hold and wait)**
     - 적어도 하나의 자원을 점유하면서 다른 프로세스에 의해 점유된 다른 자원을 요구하고 할당받기를 기다리는 프로세스가 있어야 한다.
   - **(3)비선점(Mo preemption)**
     - 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없어야한다.
     - 작업의 수행이 끝날 때까지 해당 자원을 반환하지 않는다.
   - **(4)순환 대기(Circular wait)**
     - 각 프로세스 환형 내의 이전 프로세스가 요청하는 자원을 점유와 요청해야 한다.
     - 프로세스의 집합 {P0, P1, ,…Pn}에서 P0는 P1이 점유한 자원을 대기하고 P1은 P2가 점유한 자원을 대기하고 P2…Pn-1은 Pn이 점유한 자원을 대기하며 Pn은 P0가 점유한 자원을 요구해야 한다.

   **데드락 처리**

   - **(1) 교착 상태 예방(Prevention)법**

     하벤더(Havender)가 제시한 방안

     사전에 교착 상태 발생 가능성을 없애는 방안

     - (1) 상호 배제(Mutual exclusion) 부정

       여러개의 프로세스가 공유 자원을 사용할 수 있도록 한다.

     - (2) 점유 대기(Hold and wait) 부정

       -요구한 자원을 전부 할당하여 주거나 또는 하나라도 부족하면
       전혀 할당하지 않는 방식이다.

       -프로세스가 실행되기 전 필요한 모든 자원을 할당한다.

       -한꺼번에 원하는 자원을 제공할 수 없는 경우에는 무한 연기한다.

     - (3) 비선점(No preemption) 부정

       자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 점유하고 있는 자원을 반납하고, 요구한 자원을 사용하기 위해 기다리게 한다.

     - (4) 순환 대기(Circular wait) 부정

       -자원에 고유한 번호를 할당하고, 번호 순서대로 자원을 요구하도록 한다.

       -예상한 순서와 다르게 자원을 요구하는 작업들은 실제로 자원을 사용하기 훨씬 전부터 자원을 요구/점유하고 있어야하며, 새로운 자원이 시스템에 추가되면 현존하는 프로그램과 시스템을 재작성해야한다.

   - **회피(Avoidence)법**

     교착 상태가 발생하면 피해나가는 방법

     - 은행원 알고리즘(Banker's Algorithm)

       다익스트라(Dijkstra)가 제안한 방법으로 프로세스가 자원을 요구할 때 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태를 회피하는 방법이다.

     - 문제점

       -사용 가능한 일정량의 자원이 미리 존재하도록 요구된다.

       -남아있는 사용자의 수가 수시로 변경된다.

       -모든 요청에 대하여 주어진 시간 내에서 자원을 할당할 수 있도록 더 강력한 보장이 필요하다.

       -사전에 자기가 필요한 자원의 최대량을 제시해야한다.

   - **교착상태 탐지 및 회복**

     교착 상태가 되도록 허용한 다음에 회복시키는 방법

     - 탐지 알고리즘

     - 문제점

       -시스템 교착 상태인지 알기 어렵다.

       -프로세스를 무기한 정지시키고 계속하도록하는 기능이 거의 없다.

       -상당한 추가비용이 든다.

     - 회복방법

       교착 상태에 있는 한 개 또는 그이상의 프로세스를 희생시켜 선점을 허용하는 방법이다.

       (1) 희생자(victim) 선점

        어느 프로세스를 희생 시킬지 정한다.

        희생자 선정기준은 프로세스들의 우선순위, 남은 시간, 몇 개의 프로세스 등이 있다.

       (2) 복귀(rollback) 문제

        어느 정도의 시간(범위)을 복귀시켜야 하는지 기간을 결정한다.

        처음부터 다시 시작 혹은 최소한의 시간 범위 안에서 복귀시키는 방법이 있다.

       (3) 기아현상(starvation) 문제

        반복적으로 희생자로 선정될 수 있는 가능성 문제가 있다.

        상한선을 정하고 그 값에 도달하면 더 이상 희생자가 될 수 없도록 한다.

   - **그러나 오늘날의 시스템에서 교착상태는 그리 자주 발생하지는 않는다.**

     <출처 : <https://jwprogramming.tistory.com/12?category=680235>>

     <출처 : 운영체제-박규석(생능출판사)>

     

     > 출처
     >
     > 1.운영체제-박규석(생능출판사)
     >
     > 2.<https://jwprogramming.tistory.com/12?category=680235>
     >
     > 3.<https://github.com/WeareSoft/tech-interview/blob/master/contents/os.md>
     >
     > 4.<https://jiminon5.tistory.com/46?category=620750>
     >
     > 5.http://sunrint10103.tistory.com/